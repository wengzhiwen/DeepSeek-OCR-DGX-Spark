# DeepSeek-OCR on DGX Spark (ASUS GX10)

æœ¬ä»“åº“æ˜¯ [DeepSeek-OCR](https://github.com/deepseek-ai/DeepSeek-OCR) çš„ Forkï¼Œä¸“æ³¨äºåœ¨ **NVIDIA DGX Spark (ASUS GX10)** ä¸Šé…ç½®å¯è¿è¡Œçš„åŸç”Ÿç¯å¢ƒã€‚

> ğŸ“– **åŸé¡¹ç›®**: [deepseek-ai/DeepSeek-OCR](https://github.com/deepseek-ai/DeepSeek-OCR) | [è®ºæ–‡](https://arxiv.org/abs/2510.18234) | [HuggingFace æ¨¡å‹](https://huggingface.co/deepseek-ai/DeepSeek-OCR)

## ç›®å½•

- [ç¡¬ä»¶ç¯å¢ƒ](#ç¡¬ä»¶ç¯å¢ƒ)
- [è½¯ä»¶ç‰ˆæœ¬](#è½¯ä»¶ç‰ˆæœ¬)
- [å¿«é€ŸéªŒè¯](#å¿«é€ŸéªŒè¯)
- [ä¸€ã€Transformers æ¨ç†ç¯å¢ƒ (deepseek-ocr)](#ä¸€transformers-æ¨ç†ç¯å¢ƒ-deepseek-ocr)
- [äºŒã€Transformers æ¨ç†ä½¿ç”¨](#äºŒtransformers-æ¨ç†ä½¿ç”¨)
- [ä¸‰ã€vLLM æ¨ç†ç¯å¢ƒ (deepseek-ocr-vllm)](#ä¸‰vllm-æ¨ç†ç¯å¢ƒ-deepseek-ocr-vllm)
- [å››ã€é‡åŒ– vLLM ç¯å¢ƒ (deepseek-ocr-70b-quant)](#å››é‡åŒ–-vllm-ç¯å¢ƒ-deepseek-ocr-70b-quant)
- [äº”ã€ç¯å¢ƒä½¿ç”¨æŒ‡å—](#äº”ç¯å¢ƒä½¿ç”¨æŒ‡å—)
- [å…­ã€å‚è€ƒèµ„æº](#å…­å‚è€ƒèµ„æº)

## ç¡¬ä»¶ç¯å¢ƒ

| é¡¹ç›® | é…ç½® |
|------|------|
| æœºå™¨ | ASUS GX10 (NVIDIA DGX Spark) |
| GPU | NVIDIA GB10 (Blackwell, CUDA Capability 12.1) |
| æ¶æ„ | ARM64 (aarch64) |
| é©±åŠ¨ | 580.95.05 |
| CUDA | 13.0 |

## è½¯ä»¶ç‰ˆæœ¬

ç”±äº Transformers å’Œ vLLM ç‰ˆæœ¬ä¾èµ–ä¸å…¼å®¹ï¼Œæœ¬é¡¹ç›®æä¾›ä¸¤ä¸ªç‹¬ç«‹çš„ conda ç¯å¢ƒï¼š

### ç¯å¢ƒ 1: deepseek-ocr (Transformers æ¨ç†)

| ç»„ä»¶ | ç‰ˆæœ¬ | è¯´æ˜ |
|------|------|------|
| Python | 3.12.9 | conda ç¯å¢ƒ |
| PyTorch | 2.9.0+cu130 | ARM64 + CUDA 13.0 |
| Transformers | 4.45.2 | åŒ…å« LlamaFlashAttention2 |
| Tokenizers | 0.20.3 | å…¼å®¹ Transformers 4.45.2 |
| Attention | Eager | æ ‡å‡†å®ç°ï¼ˆæ…¢ä½†ç¨³å®šï¼‰ |
| è¿è¡Œè„šæœ¬ | `run_ocr_cli.py --framework transformers` | |

**é…ç½®çŠ¶æ€**: âœ… å·²é…ç½®å®Œæˆ

### ç¯å¢ƒ 2: deepseek-ocr-vllm (vLLM æ¨ç†)

| ç»„ä»¶ | ç‰ˆæœ¬ | è¯´æ˜ |
|------|------|------|
| Python | 3.12.9 | conda ç¯å¢ƒ |
| PyTorch | 2.9.0+cu130 | ARM64 + CUDA 13.0 |
| Transformers | 4.57.3 | åŒ…å« DeepseekV3Config |
| Tokenizers | 0.22.1 | å…¼å®¹æ–°ç‰ˆ Transformers |
| vLLM | 0.11.3.dev0 | ä»æºç ç¼–è¯‘ (åŸºäº v0.11.2) |
| Triton | 3.5.0 | vLLM ä¾èµ– |
| Attention | Flash Attention | é«˜æ€§èƒ½å®ç° |
| è¿è¡Œè„šæœ¬ | `run_ocr_cli.py --framework vllm` | |

**é…ç½®çŠ¶æ€**: âœ… å·²é…ç½®å®Œæˆ

### ç¯å¢ƒ 3: deepseek-ocr-70b-quant (é‡åŒ– vLLM æ¨ç†)

| ç»„ä»¶ | ç‰ˆæœ¬ | è¯´æ˜ |
|------|------|------|
| Python | 3.12.9 | conda ç¯å¢ƒ |
| PyTorch | 2.9.0+cu130 | ARM64 + CUDA 13.0 |
| Transformers | 4.57.3 | ä¸ vLLM ç¯å¢ƒä¸€è‡´ |
| Tokenizers | 0.22.1 | ä¸ vLLM ç¯å¢ƒä¸€è‡´ |
| vLLM | 0.11.3.dev0+g275de3417.d20251204 | æºç ç¼–è¯‘ï¼ŒCUDA 13.0 |
| é‡åŒ–/åŠ é€Ÿç»„ä»¶ | bitsandbytes 0.48.2ï¼›compressed-tensors 0.12.2ï¼›flashinfer 0.5.2ï¼›gguf 0.17.1ï¼›cupy-cuda12x 13.6.0 | é¢å‘ 70B é‡åŒ–æ¨ç†çš„æ ¸å¿ƒä¾èµ– |
| CUDA åº“ | nvidia-cublas/cudnn/cusparselt/cu13 ç³»åˆ— | ä¸ GPU é©±åŠ¨/Blackwell å…¼å®¹ |
| è¿è¡Œè„šæœ¬ | `run_ocr_cli.py --framework vllm` | ç”¨äºé‡åŒ–æ¨¡å‹æ¨ç† |

**é…ç½®çŠ¶æ€**: âœ… å·²é…ç½®å®Œæˆï¼ˆä¸“ç”¨äº 70B é‡åŒ– vLLMï¼‰

### ç¯å¢ƒå¯¹æ¯”

| ç‰¹æ€§ | deepseek-ocr | deepseek-ocr-vllm |
|------|--------------|-------------------|
| **æ¨ç†å¼•æ“** | Transformers | vLLM |
| **æ€§èƒ½** | è¾ƒæ…¢ | æ›´å¿« |
| **Attention å®ç°** | Eager | Flash Attention |
| **é€‚ç”¨åœºæ™¯** | å¼€å‘æµ‹è¯• | ç”Ÿäº§éƒ¨ç½² |
| **å¹¶å‘èƒ½åŠ›** | ä½ | é«˜ (173.81x @ 8K tokens) |
| **å†…å­˜æ•ˆç‡** | ä¸€èˆ¬ | ä¼˜ç§€ (KV cache ä¼˜åŒ–) |

---

## å¿«é€ŸéªŒè¯

### éªŒè¯ç¯å¢ƒé…ç½®

éªŒè¯ä¸¤ä¸ªç¯å¢ƒæ˜¯å¦é…ç½®æ­£ç¡®ï¼š

**éªŒè¯ deepseek-ocr ç¯å¢ƒ**ï¼š
```bash
conda activate deepseek-ocr
python -c "import torch; print(f'PyTorch: {torch.__version__}, CUDA: {torch.version.cuda}')"
python -c "import transformers; print(f'Transformers: {transformers.__version__}')"
python -c "import tokenizers; print(f'Tokenizers: {tokenizers.__version__}')"
```

é¢„æœŸè¾“å‡ºï¼š
```
PyTorch: 2.9.0+cu130, CUDA: 13.0
Transformers: 4.45.2
Tokenizers: 0.20.3
```

**éªŒè¯ deepseek-ocr-vllm ç¯å¢ƒ**ï¼š
```bash
conda activate deepseek-ocr-vllm
python -c "import torch; print(f'PyTorch: {torch.__version__}, CUDA: {torch.version.cuda}')"
python -c "import transformers; print(f'Transformers: {transformers.__version__}')"
python -c "import tokenizers; print(f'Tokenizers: {tokenizers.__version__}')"
python -c "import vllm; print(f'vLLM: {vllm.__version__}')"
```

é¢„æœŸè¾“å‡ºï¼š
```
PyTorch: 2.9.0+cu130, CUDA: 13.0
Transformers: 4.57.3
Tokenizers: 0.22.1
vLLM: 0.11.3.dev0+g275de3417.d20251204
```

### éªŒè¯ OCR åŠŸèƒ½

**ä½¿ç”¨ Transformers æ¡†æ¶æµ‹è¯•**ï¼š
```bash
conda activate deepseek-ocr
python run_ocr_cli.py --framework transformers --mode random --input test_resouce/sample1
```

**ä½¿ç”¨ vLLM æ¡†æ¶æµ‹è¯•**ï¼š
```bash
conda activate deepseek-ocr-vllm
python run_ocr_cli.py --framework vllm --mode random --input test_resouce/sample1
```

å¦‚æœè¿è¡ŒæˆåŠŸï¼Œä¼šåœ¨ `results/` ç›®å½•ä¸‹ç”Ÿæˆå¸¦æ—¶é—´æˆ³çš„ç»“æœæ–‡ä»¶å¤¹ï¼ŒåŒ…å« OCR è¯†åˆ«çš„æ–‡æœ¬ã€Markdown å’Œå¸¦è¾¹ç•Œæ¡†çš„å›¾ç‰‡ã€‚

---

## ä¸€ã€Transformers æ¨ç†ç¯å¢ƒ (deepseek-ocr)

### 1.1 åˆ›å»º Conda ç¯å¢ƒ

```bash
conda create -n deepseek-ocr python=3.12.9 -y
conda activate deepseek-ocr
```

### 1.2 å®‰è£… PyTorch (CUDA 13.0 + ARM64)

**é‡è¦**: DGX Spark ä½¿ç”¨ CUDA 13.0 + ARM64 æ¶æ„ï¼Œéœ€è¦å®‰è£…å¯¹åº”ç‰ˆæœ¬çš„ PyTorchã€‚

```bash
pip install torch==2.9.0 torchvision==0.24.0 torchaudio==2.9.0 --index-url https://download.pytorch.org/whl/cu130
```

éªŒè¯å®‰è£…ï¼š
```bash
python -c "import torch; print(f'PyTorch: {torch.__version__}, CUDA: {torch.version.cuda}, GPU: {torch.cuda.get_device_name(0)}')"
```

é¢„æœŸè¾“å‡ºï¼š
```
PyTorch: 2.9.0+cu130, CUDA: 13.0, GPU: NVIDIA GB10
```

> âš ï¸ **æ³¨æ„**: ä¼šå‡ºç° CUDA capability è­¦å‘Šï¼ˆ12.1 vs 12.0ï¼‰ï¼Œè¿™æ˜¯æ­£å¸¸çš„ï¼Œä¸å½±å“ä½¿ç”¨ã€‚

### 1.3 å®‰è£… Transformers å’Œ Tokenizers

```bash
# å¿…é¡»ä½¿ç”¨ 4.45.2 ç‰ˆæœ¬ï¼Œè¯¥ç‰ˆæœ¬åŒ…å« DeepSeek-OCR æ¨¡å‹ä»£ç æ‰€éœ€çš„ LlamaFlashAttention2
pip install transformers==4.45.2 tokenizers==0.20.3
```

éªŒè¯å®‰è£…ï¼š
```bash
python -c "import transformers, tokenizers; print(f'Transformers: {transformers.__version__}, Tokenizers: {tokenizers.__version__}')"
```

é¢„æœŸè¾“å‡ºï¼š
```
Transformers: 4.45.2, Tokenizers: 0.20.3
```

### 1.4 å®‰è£…åŸºç¡€ä¾èµ–

```bash
pip install -r requirements.txt
```

### 1.5 é…ç½®ç¯å¢ƒå˜é‡ï¼ˆå¯é€‰ï¼‰

ç¯å¢ƒå˜é‡ä¼šåœ¨æ¿€æ´» conda ç¯å¢ƒæ—¶è‡ªåŠ¨è®¾ç½®ã€‚å¦‚æœæœªè‡ªåŠ¨è®¾ç½®ï¼Œè¯·æ‰‹åŠ¨åˆ›å»ºæ¿€æ´»è„šæœ¬ï¼š

```bash
mkdir -p ~/miniconda3/envs/deepseek-ocr/etc/conda/activate.d
cat > ~/miniconda3/envs/deepseek-ocr/etc/conda/activate.d/env_vars.sh << 'EOF'
#!/bin/bash
export TORCH_CUDA_ARCH_LIST="12.1a"
export TRITON_PTXAS_PATH=/usr/local/cuda/bin/ptxas
export VLLM_ALLOW_RUNTIME_LORA_UPDATING=1
echo "âœ“ DeepSeek-OCR ç¯å¢ƒå˜é‡å·²è®¾ç½®"
EOF
```

---

## äºŒã€Transformers æ¨ç†ä½¿ç”¨

Transformers æ¨ç†ç›¸å¯¹ç®€å•ï¼Œä¸éœ€è¦ç¼–è¯‘ vLLMã€‚ä¾èµ–å·²åŒ…å«åœ¨ `requirements.txt` ä¸­ã€‚

### 2.1 å…³äº FlashAttention

åœ¨ DGX Spark (GB10) ä¸Šï¼ŒFlashAttention 2.7.3 **æ— æ³•æ­£å¸¸ç¼–è¯‘**ï¼ˆBlackwell æ¶æ„æ”¯æŒé—®é¢˜ï¼‰ã€‚

**è§£å†³æ–¹æ¡ˆ**: ä½¿ç”¨ `eager` attention å®ç°ï¼š

```python
model = AutoModel.from_pretrained(
    model_name,
    _attn_implementation='eager',  # ä¸ä½¿ç”¨ flash_attention_2
    trust_remote_code=True,
    use_safetensors=True,
)
```

> âš ï¸ `eager` å®ç°é€Ÿåº¦è¾ƒæ…¢ï¼Œä½†åŠŸèƒ½å®Œæ•´ã€‚

### 2.2 è¿è¡Œ OCR è¯†åˆ«

ä½¿ç”¨ç»Ÿä¸€çš„å‘½ä»¤è¡Œå·¥å…· `run_ocr_cli.py`ï¼š

```bash
conda activate deepseek-ocr

# éšæœºå¤„ç†ä¸€å¼ å›¾ç‰‡ï¼ˆæ¨èç”¨äºæµ‹è¯•ï¼‰
python run_ocr_cli.py --framework transformers --mode random --input test_resouce/sample1

# å¤„ç†æ‰€æœ‰å›¾ç‰‡
python run_ocr_cli.py --framework transformers --mode all --input test_resouce/sample1
```

**test_resouce/sample1**æ˜¯ä¸€ä¸ªè£…ç€æ•°å¼ å›¾ç‰‡çš„æ–‡ä»¶å¤¹

### 2.3 è¿è¡Œæ¨¡å¼

| æ¨¡å¼ | base_size | image_size | crop_mode | vision tokens |
|------|-----------|------------|-----------|---------------|
| Tiny | 512 | 512 | False | 64 |
| Small | 640 | 640 | False | 100 |
| Base | 1024 | 1024 | False | 256 |
| **Large** | 1280 | 1280 | False | 400 |
| Gundam | 1024 | 640 | True | åŠ¨æ€ |

---

## ä¸‰ã€vLLM æ¨ç†ç¯å¢ƒ (deepseek-ocr-vllm)

### 3.1 ä¸ºä»€ä¹ˆéœ€è¦ç‹¬ç«‹ç¯å¢ƒï¼Ÿ

Transformers å’Œ vLLM å¯¹ä¾èµ–ç‰ˆæœ¬è¦æ±‚ä¸å…¼å®¹ï¼š

| ä¾èµ– | Transformers ç¯å¢ƒ | vLLM ç¯å¢ƒ |
|------|------------------|----------|
| transformers | 4.45.2ï¼ˆå« LlamaFlashAttention2ï¼‰ | 4.56.0+ï¼ˆå« DeepseekV3Configï¼‰ |
| tokenizers | 0.20.3 | 0.21.1+ |

å› æ­¤éœ€è¦åˆ›å»ºç‹¬ç«‹çš„ `deepseek-ocr-vllm` ç¯å¢ƒã€‚

### 3.2 åˆ›å»º Conda ç¯å¢ƒ

```bash
conda create -n deepseek-ocr-vllm python=3.12.9 -y
conda activate deepseek-ocr-vllm
```

### 3.3 å®‰è£… PyTorch (CUDA 13.0 + ARM64)

```bash
pip install torch==2.9.0 torchvision==0.24.0 torchaudio==2.9.0 --index-url https://download.pytorch.org/whl/cu130
```

### 3.4 å®‰è£… Transformers å’Œ Tokenizers

```bash
# vLLM éœ€è¦è¾ƒæ–°ç‰ˆæœ¬çš„ transformersï¼ˆä¼šè‡ªåŠ¨å®‰è£…æœ€æ–°ç‰ˆæœ¬ï¼‰
pip install 'transformers>=4.56.0' 'tokenizers>=0.21.1'
```

éªŒè¯å®‰è£…ï¼š
```bash
python -c "import transformers, tokenizers; print(f'Transformers: {transformers.__version__}, Tokenizers: {tokenizers.__version__}')"
```

é¢„æœŸè¾“å‡ºï¼š
```
Transformers: 4.57.3, Tokenizers: 0.22.1
```

### 3.5 å®‰è£…åŸºç¡€ä¾èµ–

```bash
pip install -r requirements.txt
```

### 3.6 é…ç½®ç¯å¢ƒå˜é‡

åˆ›å»ºç¯å¢ƒæ¿€æ´»è„šæœ¬ï¼š

```bash
mkdir -p ~/miniconda3/envs/deepseek-ocr-vllm/etc/conda/activate.d
cat > ~/miniconda3/envs/deepseek-ocr-vllm/etc/conda/activate.d/env_vars.sh << 'EOF'
#!/bin/bash
export TORCH_CUDA_ARCH_LIST="12.1a"
export TRITON_PTXAS_PATH=/usr/local/cuda/bin/ptxas
export VLLM_ALLOW_RUNTIME_LORA_UPDATING=1
echo "âœ“ DeepSeek-OCR-vLLM ç¯å¢ƒå˜é‡å·²è®¾ç½®"
EOF
```

### 3.7 ä¸ºä»€ä¹ˆéœ€è¦æºç ç¼–è¯‘ vLLMï¼Ÿ

vLLM å®˜æ–¹é¢„ç¼–è¯‘çš„ wheel åŒ…æ˜¯åŸºäº **CUDA 12.x + x86_64** çš„ï¼Œåœ¨ DGX Spark ä¸Šä¼šé‡åˆ°ï¼š

1. **æ¶æ„ä¸åŒ¹é…**: é¢„ç¼–è¯‘åŒ…æ˜¯ x86_64ï¼ŒDGX Spark æ˜¯ ARM64 (aarch64)
2. **CUDA ç‰ˆæœ¬ä¸åŒ¹é…**: é¢„ç¼–è¯‘åŒ…åŸºäº CUDA 12.xï¼ŒDGX Spark æ˜¯ CUDA 13.0
3. **ç¬¦å·ç‰ˆæœ¬é—®é¢˜**: å³ä½¿ä½¿ç”¨å…¼å®¹å±‚ä¹Ÿæ— æ³•è§£å†³ `libcudart.so.12` ç¬¦å·ç‰ˆæœ¬é—®é¢˜

**è§£å†³æ–¹æ¡ˆ**: ä»æºç ç¼–è¯‘ vLLMã€‚

### 3.8 å‡†å¤‡ç¼–è¯‘å·¥å…·

```bash
# ç¡®ä¿å·²æ¿€æ´» vLLM ç¯å¢ƒ
conda activate deepseek-ocr-vllm

# å®‰è£…ç¼–è¯‘ä¾èµ–
pip install cmake ninja pybind11 setuptools wheel setuptools_scm
```

### 3.9 è·å– vLLM æºç 

```bash
mkdir -p ~/vllm-install
cd ~/vllm-install
git clone --recursive https://github.com/vllm-project/vllm.git
cd vllm
git checkout v0.11.2
git submodule update --init --recursive
```

### 3.10 ä¿®å¤ pyproject.toml

vLLM v0.11.2 çš„ `pyproject.toml` éœ€è¦ä¿®å¤ license å­—æ®µæ ¼å¼ï¼š

```bash
cd ~/vllm-install/vllm
sed -i 's/^license = "Apache-2.0"$/license = {text = "Apache-2.0"}/' pyproject.toml
sed -i '/^license-files = /d' pyproject.toml
```

### 3.11 ç¼–è¯‘å®‰è£…

```bash
cd ~/vllm-install/vllm

# ç¼–è¯‘å®‰è£…ï¼ˆçº¦ 15-20 åˆ†é’Ÿï¼‰
# æ³¨æ„ï¼šç¯å¢ƒå˜é‡å·²åœ¨ conda ç¯å¢ƒæ¿€æ´»æ—¶è‡ªåŠ¨è®¾ç½®ï¼Œæ— éœ€æ‰‹åŠ¨ export
pip install --no-build-isolation -e .
```

### 3.12 éªŒè¯å®‰è£…

```bash
python -c "import vllm; print(f'vLLM: {vllm.__version__}')"
python -c "from vllm.model_executor.models.deepseek_ocr import NGramPerReqLogitsProcessor; print('DeepSeek-OCR support: OK')"
```

é¢„æœŸè¾“å‡ºï¼š
```
vLLM: 0.11.3.dev0+g275de3417.d20251204
DeepSeek-OCR support: OK
```

> **å…³äºç‰ˆæœ¬å·**: checkout `v0.11.2` ä½†æ˜¾ç¤º `0.11.3.dev0` æ˜¯æ­£å¸¸çš„ã€‚vLLM ä½¿ç”¨ `setuptools_scm` ä» git è‡ªåŠ¨ç”Ÿæˆç‰ˆæœ¬å·ï¼Œæ ¼å¼ä¸º `{next_version}.dev{distance}+g{commit}`ã€‚v0.11.2 tag ä¹‹åçš„ä¸‹ä¸€ä¸ªç‰ˆæœ¬æ˜¯ 0.11.3ï¼Œæ‰€ä»¥æ˜¾ç¤ºä¸º dev ç‰ˆæœ¬ã€‚

### 3.13 è¿è¡Œ OCR è¯†åˆ«

ä½¿ç”¨ç»Ÿä¸€çš„å‘½ä»¤è¡Œå·¥å…· `run_ocr_cli.py`ï¼š

```bash
conda activate deepseek-ocr-vllm

# éšæœºå¤„ç†ä¸€å¼ å›¾ç‰‡ï¼ˆæ¨èç”¨äºæµ‹è¯•ï¼‰
python run_ocr_cli.py --framework vllm --mode random --input test_resouce/sample1

# å¤„ç†æ‰€æœ‰å›¾ç‰‡ï¼ˆæ¨èç”¨äºæ‰¹é‡å¤„ç†ï¼‰
python run_ocr_cli.py --framework vllm --mode all --input test_resouce/sample1
```

**vLLM é»˜è®¤ä½¿ç”¨ Gundam æ¨¡å¼**ï¼ˆç¡¬ç¼–ç åœ¨æºç ä¸­ï¼‰ï¼Œé€‚åˆå¤„ç†å¤§å°ºå¯¸æ–‡æ¡£å›¾ç‰‡ã€‚

---

## å››ã€é‡åŒ– vLLM ç¯å¢ƒ (deepseek-ocr-70b-quant)

ä¸“é—¨ç”¨äº 70B é‡åŒ–æ¨¡å‹çš„ vLLM æ¨ç†ç¯å¢ƒï¼ŒåŸºäºæºç ç¼–è¯‘çš„ CUDA 13.0 ç‰ˆæœ¬ï¼Œå¹¶é¢„ç½®å¸¸ç”¨é‡åŒ–/åŠ é€Ÿç»„ä»¶ã€‚

- æ ¸å¿ƒç‰ˆæœ¬ï¼šPython 3.12.9ï¼›PyTorch 2.9.0+cu130ï¼›vLLM 0.11.3.dev0+g275de3417.d20251204ï¼›Transformers 4.57.3ï¼›Tokenizers 0.22.1ã€‚
- é‡åŒ–/åŠ é€Ÿç»„ä»¶ï¼šbitsandbytes 0.48.2ã€compressed-tensors 0.12.2ã€flashinfer 0.5.2ã€gguf 0.17.1ã€cupy-cuda12x 13.6.0ï¼›CUDA 13.0 çš„ nvidia-cu*ã€cudnnã€cusparselt åº“å·²å°±ä½ã€‚
- è¾…åŠ©å·¥å…·ï¼šaccelerate 1.12.0ã€optimum 2.0.0ã€tiktoken 0.12.0 ç­‰ï¼Œä¾¿äºé‡åŒ–æƒé‡åŠ è½½ä¸é«˜ååæ¨ç†ã€‚
- ä½¿ç”¨æ–¹å¼ï¼š`conda activate deepseek-ocr-70b-quant` åä¸ `deepseek-ocr-vllm` ç›¸åŒï¼Œç›´æ¥è¿è¡Œ `python run_ocr_cli.py --framework vllm ...`ã€‚
- å¿«é€Ÿæ ¡éªŒï¼ˆå¯é€‰ï¼‰ï¼š
```bash
conda activate deepseek-ocr-70b-quant
python - <<'PY'
import torch, vllm, bitsandbytes, flashinfer
print("Torch:", torch.__version__, "CUDA:", torch.version.cuda)
print("vLLM:", vllm.__version__)
print("bitsandbytes:", bitsandbytes.__version__)
print("flashinfer:", flashinfer.__version__)
PY
```

---

## äº”ã€ç¯å¢ƒä½¿ç”¨æŒ‡å—

### 5.1 å¦‚ä½•é€‰æ‹©ç¯å¢ƒ

| åœºæ™¯ | æ¨èç¯å¢ƒ | åŸå›  |
|------|---------|------|
| å¼€å‘è°ƒè¯• | deepseek-ocr | ç®€å•ç›´æ¥ï¼Œä¾¿äºè°ƒè¯• |
| ç”Ÿäº§éƒ¨ç½² | deepseek-ocr-vllm | æ€§èƒ½æ›´å¥½ï¼Œæ”¯æŒé«˜å¹¶å‘ |
| å•å¼ å›¾ç‰‡å¤„ç† | deepseek-ocr | å¯åŠ¨å¿«ï¼Œæ— éœ€é¢„çƒ­ |
| æ‰¹é‡å¤„ç† | deepseek-ocr-vllm | ååé‡é«˜ï¼Œå†…å­˜æ•ˆç‡å¥½ |
| é¦–æ¬¡ä½¿ç”¨ | deepseek-ocr | é…ç½®ç®€å•ï¼Œä¾èµ–å°‘ |

### 5.2 ç¯å¢ƒåˆ‡æ¢å’Œä½¿ç”¨

```bash
# åˆ‡æ¢åˆ° Transformers ç¯å¢ƒ
conda activate deepseek-ocr
python run_ocr_cli.py --framework transformers --mode random --input test_resouce/sample1

# åˆ‡æ¢åˆ° vLLM ç¯å¢ƒ
conda activate deepseek-ocr-vllm
python run_ocr_cli.py --framework vllm --mode all --input test_resouce/sample1

# åˆ‡æ¢åˆ°é‡åŒ– vLLM ç¯å¢ƒï¼ˆåŒæ ·ä½¿ç”¨ vllm æ¡†æ¶ï¼‰
conda activate deepseek-ocr-70b-quant
python run_ocr_cli.py --framework vllm --mode all --input test_resouce/sample1
```

**å‘½ä»¤è¡Œå‚æ•°è¯´æ˜**ï¼š
- `--framework`: å¿…é€‰ï¼ŒæŒ‡å®šä½¿ç”¨çš„æ¡†æ¶ï¼ˆ`transformers` æˆ– `vllm`ï¼‰
- `--mode`: å¯é€‰ï¼Œå·¥ä½œæ¨¡å¼ï¼ˆ`random` éšæœºé€‰æ‹©1å¼ ï¼Œ`all` å¤„ç†æ‰€æœ‰å›¾ç‰‡ï¼Œé»˜è®¤ `random`ï¼‰
- `--input`: å¯é€‰ï¼Œè¾“å…¥ç›®å½•è·¯å¾„ï¼ˆé»˜è®¤ `test_resouce/sample1`ï¼‰
- `--output`: å¯é€‰ï¼Œè¾“å‡ºåŸºç¡€ç›®å½•ï¼ˆé»˜è®¤ `results`ï¼‰

æŸ¥çœ‹å®Œæ•´å¸®åŠ©ï¼š
```bash
python run_ocr_cli.py --help
```

### 5.3 ç¯å¢ƒç»´æŠ¤

**æŸ¥çœ‹å·²å®‰è£…çš„ç¯å¢ƒ**ï¼š
```bash
conda env list
```

**æ›´æ–°ä¾èµ–**ï¼š
```bash
# Transformers ç¯å¢ƒ
conda activate deepseek-ocr
pip install -r requirements.txt --upgrade

# vLLM ç¯å¢ƒ
conda activate deepseek-ocr-vllm
pip install -r requirements.txt --upgrade
```

**åˆ é™¤ç¯å¢ƒ**ï¼ˆå¦‚éœ€é‡æ–°é…ç½®ï¼‰ï¼š
```bash
conda remove -n deepseek-ocr --all
conda remove -n deepseek-ocr-vllm --all
conda remove -n deepseek-ocr-70b-quant --all
```

### 5.4 ç¯å¢ƒå˜é‡è¯´æ˜

ä¸‰å¥—ç¯å¢ƒå…±äº«åŒä¸€ç»„ CUDA/Triton å˜é‡ï¼ˆåœ¨å„è‡ªçš„ conda activate è„šæœ¬ä¸­è®¾ç½®ï¼‰ï¼š

| å˜é‡å | å€¼ | ä½œç”¨ |
|--------|-----|------|
| `TORCH_CUDA_ARCH_LIST` | `12.1a` | æŒ‡å®š CUDA æ¶æ„ï¼ˆGB10ï¼‰ |
| `TRITON_PTXAS_PATH` | `/usr/local/cuda/bin/ptxas` | Triton ç¼–è¯‘å™¨è·¯å¾„ |
| `VLLM_ALLOW_RUNTIME_LORA_UPDATING` | `1` | å…è®¸ vLLM è¿è¡Œæ—¶æ›´æ–° |

è¿™äº›å˜é‡ç”¨äºè§£å†³ Blackwell æ¶æ„ï¼ˆGB10ï¼‰çš„ Triton ç¼–è¯‘é—®é¢˜ã€‚

---

## å…­ã€å‚è€ƒèµ„æº

- [DeepSeek-OCR å®˜æ–¹ä»“åº“](https://github.com/deepseek-ai/DeepSeek-OCR)
- [vLLM å®˜æ–¹æ–‡æ¡£](https://docs.vllm.ai/)
- [vLLM DeepSeek-OCR æ”¯æŒ](https://docs.vllm.ai/projects/recipes/en/latest/DeepSeek/DeepSeek-OCR.html)
- [HuggingFace æ¨¡å‹](https://huggingface.co/deepseek-ai/DeepSeek-OCR)
- [è®ºæ–‡ (arXiv)](https://arxiv.org/abs/2510.18234)

---

## i18n

### English Summary

**DeepSeek-OCR on NVIDIA DGX Spark (ASUS GX10)**

This repository is a fork of [DeepSeek-OCR](https://github.com/deepseek-ai/DeepSeek-OCR), optimized for running on **NVIDIA DGX Spark (ASUS GX10)** with native ARM64 + CUDA 13.0 support.

**Key Features:**
- âœ… Three conda environments: Transformers, vLLM, and quantized vLLM (70B)
- âœ… Full support for NVIDIA GB10 (Blackwell architecture, CUDA Capability 12.1)
- âœ… Pre-configured environment variables for Triton compilation
- âœ… Unified CLI tool (`run_ocr_cli.py`) supporting both frameworks
- âœ… Batch processing and random sampling modes

**Hardware Requirements:**
- Machine: ASUS GX10 (NVIDIA DGX Spark)
- GPU: NVIDIA GB10 (Blackwell, CUDA Capability 12.1)
- Architecture: ARM64 (aarch64)
- CUDA: 13.0

**Software Stack:**
- **deepseek-ocr**: Transformers 4.45.2, Python 3.12.9, PyTorch 2.9.0+cu130
- **deepseek-ocr-vllm**: Transformers 4.57.3, vLLM 0.11.3.dev0 (compiled from source), Python 3.12.9
- **deepseek-ocr-70b-quant**: Same vLLM stack + quantization helpers (bitsandbytes, compressed-tensors, flashinfer, gguf)

**Quick Start:**
```bash
# Transformers framework
conda activate deepseek-ocr
python run_ocr_cli.py --framework transformers --mode random

# vLLM framework
conda activate deepseek-ocr-vllm
python run_ocr_cli.py --framework vllm --mode all
```

---

### æ—¥æœ¬èªæ¦‚è¦

**NVIDIA DGX Spark (ASUS GX10) ã§ã® DeepSeek-OCR**

ã“ã®ãƒªãƒã‚¸ãƒˆãƒªã¯ [DeepSeek-OCR](https://github.com/deepseek-ai/DeepSeek-OCR) ã®ãƒ•ã‚©ãƒ¼ã‚¯ã§ã€**NVIDIA DGX Spark (ASUS GX10)** ä¸Šã§ ARM64 + CUDA 13.0 ã®ãƒã‚¤ãƒ†ã‚£ãƒ–ã‚µãƒãƒ¼ãƒˆã§å‹•ä½œã™ã‚‹ã‚ˆã†ã«æœ€é©åŒ–ã•ã‚Œã¦ã„ã¾ã™ã€‚

**ä¸»ãªç‰¹å¾´:**
- âœ… Transformers ã¨ vLLM æ¨è«–ç”¨ã®2ã¤ã®ç‹¬ç«‹ã—ãŸ conda ç’°å¢ƒ
- âœ… NVIDIA GB10 (Blackwell ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã€CUDA Capability 12.1) ã®å®Œå…¨ã‚µãƒãƒ¼ãƒˆ
- âœ… Triton ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ç”¨ã®äº‹å‰è¨­å®šæ¸ˆã¿ç’°å¢ƒå¤‰æ•°
- âœ… ä¸¡ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ã‚µãƒãƒ¼ãƒˆã™ã‚‹çµ±ä¸€ CLI ãƒ„ãƒ¼ãƒ« (`run_ocr_cli.py`)
- âœ… ãƒãƒƒãƒå‡¦ç†ã¨ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ¢ãƒ¼ãƒ‰

**ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢è¦ä»¶:**
- ãƒã‚·ãƒ³: ASUS GX10 (NVIDIA DGX Spark)
- GPU: NVIDIA GB10 (Blackwellã€CUDA Capability 12.1)
- ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£: ARM64 (aarch64)
- CUDA: 13.0

**ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚¹ã‚¿ãƒƒã‚¯:**
- **deepseek-ocr**: Transformers 4.45.2ã€Python 3.12.9ã€PyTorch 2.9.0+cu130
- **deepseek-ocr-vllm**: Transformers 4.57.3ã€vLLM 0.11.3.dev0 (ã‚½ãƒ¼ã‚¹ã‹ã‚‰ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«)ã€Python 3.12.9

**ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ:**
```bash
# Transformers ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯
conda activate deepseek-ocr
python run_ocr_cli.py --framework transformers --mode random

# vLLM ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯
conda activate deepseek-ocr-vllm
python run_ocr_cli.py --framework vllm --mode all
```
